---
layout: post
title:  "สรุปแนวคิด Neural Network แบบไม่มี Math"
subtitle: "เข้าใจพื้นฐานของ Machine Learning แบบ Neural Network โดยไม่ต้องรู้ Math !!"
description: "เข้าใจพื้นฐานของ Neural Network โดยไม่ต้องอาศัยความรู้ Math และลองเล่นเบื้องต้นบนจาวาสคริปด้วย Synaptic.js"
date:   2017-02-22 06:00:00 +0700
categories: machine-learning neural-network
image: /assets/images/thumbnail/neural-network-thumb.png
top_three: true
highlight_color: "#17B890"
---

ในโลกของ Developer ทุกวันนี้ ทุกคนคงจะได้ยินเทรนด์ในการพัฒนาซอฟแวร์ยุคใหม่ที่อยู่บนพื้นฐานของ machine learning หรือที่หลายๆคนเรียกว่า `AI-first` ซึ่งจะเข้ามาแทนยุค Mobile-first ในปัจจุบัน

ในส่วนพื้นฐานล่างสุดของการทำ Machine Leaning นั้น คือส่วนที่เรียกว่า Neural network หรือโครงข่ายประสาทเทียม ซึ่งหลายๆคนที่เข้ามาลองหาข้อมูลในด้านนี้คงเห็นว่าแล้ว มันอิงกับคณิตศาสตร์ค่อนข้างมาก เปิดเล่มไหนก็จะเจอ `Math` หรือไปลองใช้ Library ก็จะพบว่า มันคืออะไรก็ไม่รู้ เต็มไปหมด แม้จะไม่มี Math ก็ตาม แล้ว Developer ผู้อ่อนด๋อยในคณิตศาสตร์แบบพวกเราจะเข้าใจมันได้อย่างไร เดี๋ยวผมจะมาอธิบายพื้นฐานแนวคิดและการทำงาน เพื่อที่เราจะได้เข้าใจแบบง่ายๆ และนำไปปรับใช้งานกับ Library ได้อย่างเข้าใจนะครับ

## Neural Network
คือโครงข่ายประสามเทียมที่เป็นการ`จำลองมาจากสมอง`ของเรา โดยสมองของเรานั้นจะมีหน่วยประมวลผลขนาดเล็กอยู่เยอะมาก และเชื่อมโยงกันด้วยโครงข่ายประสาทมากมาย ช่วยให้เราได้เรียนรู้และคิดวิเคราะห์ได้อย่างรวดเร็ว

แต่ในส่วนคอมพิวเตอร์นั้นไม่ได้มีโครงข่ายที่ซับซ้อนเหมือนกับสมองของเรา มันมีหน้าที่แค่รันโปรแกรมตามคำสั่งของเราเท่านั้น ดังนั้นเมื่อเราจะให้มันทำการเรียนรู้อะไรซักอย่าง จึงเป็นเรื่องยากในรูปแบบปกติ จึงเกิดการจำลองแนวทางการเรียนรู้ของคน ไปสู่คอมพิวเตอร์ด้วย Neural Network นั่นเอง

## Human Learning
ในการเรียนรู้ของมนุษย์นั้น มีหลายวิธี หนึ่งในนั้นคือการที่เรารับข้อมูลมา และรับรู้ว่าข้อมูลนั้นคืออะไร จากนั้นเราก็จะจำและเรียนรู้ในการรับรู้ในสิ่งที่คล้ายๆกัน 

เช่น ในตอนที่เราเกิดมา เราไม่รู้ว่าหมาคืออะไร แต่เราได้เห็น จากนั้นพ่อแม่เราก็บอกว่านี่คือ “หมา” นะ สมองของแต่ละคนก็จะ`หาวิธีจดจำว่ารูปแบบข้อมูลลักษณะนี้`คือ หมา เช่น มีสี่ขา มีขน เห่าได้ อะไรพวกนี้ 

![Human Learning](/assets/images/posts/neuron/human-learning.png)

ทีนี้เมื่อเราได้เห็น “แมว” และพ่อแม่เราบอกว่า มันคือ “แมว” เราก็จะรับรู้เป็นข้อมูลอีกชุดนึง ซึ่งสมองของเราก็จะเรียนรู้และ`หาวิธีแยกแยะข้อแตกต่างของหมาและแมวได้` และยิ่งเมื่อเราเห็นหมาและแมวบ่อยๆ และในรูปแบบที่แตกต่างกันเล็กน้อยมากขึ้นเท่าไหร่ เราก็จะสามารถแยกแยะ “หมา” และ “แมว” ได้ถูกต้องยิ่งขึ้น

จะเห็นได้ว่า เราเรียนรู้จากการป้อนข้อมูลรายละเอียด ( มองเห็นหมาและแมว ) และการป้อนข้อมูลผลลัพธ์ ( พ่อแม่บอกว่านี่คือหมาหรือแมว ) ซึ่งในส่วนของการจดจำรูปแบบและรับรู้นั้น เป็นสิ่งที่เราคิดขึ้นมาเอง และ Neural Network ก็นำ`แนวคิด`นี้มาใช้ช่วยให้คอมพิวเตอร์ สามารถที่จะเรียนรู้ได้นั่นเอง

### Machine vs Machine Learning
การรันโปรแกรมคอมพิวเตอร์ทั่วไปนั้น เกิดจากการที่เราเขียนโปรแกรมระบุการทำงานให้ เช่น หากเราจะเขียนโปรแกรมแยกแยะหมาและแมว เราต้องบอกมันว่า เราจะแยก หมา และ แมว ได้ด้วยวิธีไหน

```
function isDogOrCat(input) {
	if(input === "Dog Detail") {
		return "Dog"
	} else if(input === "Cat Detail") {
		return "Cat"
	} else {
		return "None"
	}
}
```

ซึ่งเราจะเห็นว่า Machine นั้นไม่จำเป็นต้องเรียนรู้อะไร เพียงแค่ทำงานตามคำสั่งไปเท่านั้น

แต่เมื่อเราปรับให้เป็น Machine Learning นั้น ก็เหมือนเราจำลองการทำ Human Learning แบบข้างต้น โดยเราจำไม่เขียนโปรแกรมแบบระบุการทำงานตรงๆ แต่เราจะให้ `Input` และ `Output` เข้าไป เพื่อสอนตัวคอมพิวเตอร์ ให้มันพัฒนาตัวเองและเรียนรู้ จากนั้นเมื่อเราให้ Input ใหม่เข้าไป ตัว Machine Learning ก็จะให้คำตอบออกมาโดย`อ้างอิงจากสิ่งที่มันได้เรียนรู้ไปแล้ว`นั่นเอง


## Neuron
ส่วนที่เล็กที่สุดของ Neural Network ก็คือ `Neuron` ซึ่งทำหน้าที่คำนวน input ที่เข้ามา เพื่อให้ได้ผลลัพธ์ออกไป โดยมีส่วนประกอบสำคัญดังนี้

- `Input` หรือค่าที่ส่งเข้ามาที่ Neuron โดยจะมีขาที่เข้ามาได้หลายขา ขึ้นอยู่กับเราจะสร้าง
- `Weight` เป็นการให้น้ำหนักของขาแต่ละที่ส่งเข้ามา โดยมีค่าระหว่าง 0-1 เมื่อเริ่มต้นจะเป็นการ Random ขึ้นมา จากนั้นตัว Neuron เมื่อทำการเรียนรู้เรื่อยๆ ก็จะเป็นการปรับ weight ตัวแหละ ให้มันได้คำตอบที่ใกล้เคียงที่สุด
- `Bias` คือค่าที่จะช่วยเข้ามาทำให้ค่าที่เข้ามาอยู่ในระหว่าง 0 - 1 ได้ โดยจะเป็นเลข random และปรับไปเรื่อยๆทุกครั้งที่เรียนรู้ 
- `Output` คือผลลัพธ์
- `Back Propagation` คือการที่ Neuron นำค่า Error ของ Output ที่ได้ กับ Output ที่เราสั่งให้มันเรียนรู้ นำไปปรับ Weight และ Bias ให้เกิดผลลัพธ์ที่ถูกต้องตามที่ได้เรียนรู้มา

มาดูเป็นภาพกันดีกว่า

![Neuron](/assets/images/posts/neuron/neuron1.png)

เมื่อทำการสร้างตัว  Neuron ขึ้น ตัว Neuron ก็จะมาดูว่า มี Input ขาไหนบ้าง จากนั้นกำหนด Weight ของขา Input แต่ละขา โดยเป็นค่า Random จาก 0 - 1

![Random Weight](/assets/images/posts/neuron/neuron2.png)

จากนั้นเมื่อเราป้อน Input และ Output ให้มัน เพื่อทำการเรียนรู้ ตัว Neuron ก็จะทำการ Sum ตัว Input ด้วย Weight คูณกับค่าที่มาของแต่ละขา จากนั้นบวกค่าอื่นๆ เช่น bias แล้วนำไปเข้าฟังก์ชันที่ตัว Neuron นั้นกำหนดไว้ ก็จะเป็น Output ที่ผ่านการคำนวนออกมานะครับ โดยฟังก์ชันก็จะมีหลายแบบขึ้นอยู่รูปแบบที่จะนำไปใช้งาน เช่น `Sigmoid`, `Hyperbolic Tangens`, `Hard Limit`, `Rectified Linear Unit` เป็นต้น  โดยในตัวอย่างจะเป็น Sigmoid นะครับเนื่องจากง่ายที่สุด และเป็นฟังก์ชันพื้นฐานในหลายๆ Library ครับ

ทีนี้จะมาดูวิธีการเรียนรู้ของมันกันบ้าง โจทย์คือเราต้องการให้มันเรียนรู้การทำงานของ XOR

| Input 1  	| Input 2		 | Output		 	|
| --------- | ---------- | ---------- | 
| 1    			| 1 				 | 1 				  |
| 1    			| 1 				 | 1 				  |
| 0   			| 1 				 | 1 				  |
| 0    			| 0 				 | 0 				  |

| Input  		| Weight		 | Bias		 		|
| --------- | ---------- | ---------- | 
| Input 1   | 0.7 			 | 0.56 			|
| Input 2   | 0.4 			 | 0.56 			|

เมื่อเราทำการสอนในแต่ละครั้ง เราก็จะกำหนด Input และ Output ให้ตัว Neuron จากนั้นตัว Neuron ก็จะไปคำนวนและเก็บ State เพื่อที่จะปรับปรุงการคำนวนในครั้งถัดไปให้ได้ผลลัพธ์ตามข้อมูลที่ได้รับมา

Input [1,1] : Output [1]

![Sum Input](/assets/images/posts/neuron/neuron3.png)

```
	   Input 1 	    Input 2
fn( ( 1 * 0.7 ) + ( 1 * 0.4 ) + bias ) = output;
```

จะเห็นได้ว่า Output ที่ตัว Neuron นั้นคำนวนได้ และ Output ที่เราสอนมันนั้น ไม่ตรงกัน มีความคลาดเคลื่อน หรือเราจะเรียกว่ามันเกิด `Error` เมื่อมีความคลาดเคลื่อน ตัว Neuron ก็จะทำการ Back Propagation หรือการนำค่า Error นั้นมาปรับค่า Weight และ Bias ใหม่นั่นเอง เช่น ในกรณีนี้คลาดเคลื่อนไป `0.25` ก็จะนำไปเข้าสมการโน้นนี่นั้น แล้วนำค่าที่ได้มาปรับ Weight เช่น Weight ใหม่อาจจะเป็น `0.75` และ `0.45` เป็นต้น

| Input  		| Weight		 | Bias		 		|
| --------- | ---------- | ---------- | 
| Input 1   | 0.75 			 | 0.54 			|
| Input 2   | 0.45 			 | 0.54 			|

จากนั้นเราก็จะสอนตัว Neuron ไปเรื่อยๆ ตัว Weight ที่ได้ก็จะทำให้ผลลัพธ์ออกมาใกล้เคียงที่สุดนั่นเอง

![Sum Input2](/assets/images/posts/neuron/neuron4.png)

```
	   Input 1 	      Input 2
fn( ( 1 * 0.75 ) + ( 0 * 0.45 ) + bias ) = output;
```

ดังนั้นการสอนตัว Neuron นั้นจำเป็นต้องสอนหลายๆรอบเพื่อให้เกิด Error น้อยที่สุดนะครับ

ลอง Train ไปซัก 10 รอบ ผลก็จะออกมาเป็น

| Input  		| Weight		 | Bias		 		|
| --------- | ---------- | ---------- | 
| Input 1   | 1.28 		 	 | 0.196			|
| Input 2   | 1.21 		 	 | 0.196 			|

| Input 1  	| Input 2		 | Output		 	|
| --------- | ---------- | ---------- | 
| 1    			| 1 				 | 0.936 			|
| 1    			| 1 				 | 0.814 			|
| 0   			| 1 				 | 0.814 			|
| 0    			| 0 				 | 0.549 			|

ทีนี้มาลอง Train ไปซัก 100 รอบ ผลก็จะออกมาเป็น

| Input  		| Weight		 | Bias		 		|
| --------- | ---------- | ---------- | 
| Input 1   | 4.424 		 | -1.709			|
| Input 2   | 4.401 		 | -1.709 		|

| Input 1  	| Input 2		 | Output		 	|
| --------- | ---------- | ---------- | 
| 1    			| 1 				 | 0.999 			|
| 1    			| 1 				 | 0.937 			|
| 0   			| 1 				 | 0.937 			|
| 0    			| 0 				 | 0.153 			|

ลอง Train เพิ่มเป็นซัก 1000 รอบ ผลก็จะออกมาเป็น

| Input  		| Weight		 | Bias		 		|
| --------- | ---------- | ---------- | 
| Input 1   | 9.05 			 | -4.06			|
| Input 2   | 9.04 			 | -4.06 			|

| Input 1  	| Input 2		 | Output		 	|
| --------- | ---------- | ---------- | 
| 1    			| 1 				 | 0.999 			|
| 1    			| 1 				 | 0.993 			|
| 0   			| 1 				 | 0.993 			|
| 0    			| 0 				 | 0.016 			|

จะเห็นได้ว่า ยิ่งเรา Train มากเท่าไหร่ ตัว Weight และ Bias ก็จะปรับค่าให้ได้ Output ที่ใกล้เคียงผลลัพธ์ที่เราต้องการมากที่สุดนั่นเอง

## Neural Network

แน่นอนว่าทำงานคนเดียว ก็จะได้งานแค่ระดับนึง แต่ถ้างานใหญ่มาก ยังไงก็ต้องทำงานเป็นทีม Neuron ก็เช่นกัน ตัวเดียวก็ให้ Output ได้แค่ 0 1 ดังนั้น เราจึงต้องใช้ Neuron หลายตัวในการช่วยกันเรียนรู้นั่นเอง

### Feed-Forward Neural Network

รูปแบบของ Neural Network ที่ง่ายที่สุดคือ Feed-Forward Neural Network โดยจะแบ่ง Neuron ออกเป็นกลุ่มๆ โดยแต่ละกลุ่มจะเรียกเป็น `Layer` โดยข้อมูลที่เข้ามาจะไหลไปในทิศทางเดียว ไม่ไหลย้อนกลับ จาก Layer นึงสู่อีก Layer นึง

![Feed Forward Neural Network](/assets/images/posts/neuron/feed-forward.png)

## Neuron Workshop with Synaptic.js

มาลอง Implement Neural Network แบบง่ายๆบน Javascripts กันนะครับ โดย Library ที่ผมเลือกนำมาใช้คือ Synaptic.js โดยเราจะมาทำฟังก์ชัน `XOR` ด้วย Neuron เท่านั้นนะครับ

```
const { Neuron } = require('synaptic');

let A = new Neuron();
let B = new Neuron();
let C = new Neuron();

A.project(C);
B.project(C);

let learningRate = 0.3;

/* Train Neuron for 10000 Loop */
for(let i = 0; i < 10000; i++) {
	/* Input [1,1] */
	A.activate(1);
	B.activate(1);

	/* Train to Output 1 */
	C.activate();
	C.propagate(learningRate, 1);

	/* Input [1,0] */
	A.activate(1);
	B.activate(0);

	/* Train to Output 1 */
	C.activate();
	C.propagate(learningRate, 1);

	/* Input [0,1] */
	A.activate(0);
	B.activate(1);

	/* Train to Output 1 */
	C.activate();
	C.propagate(learningRate, 1);

	/* Input [0,0] */
	A.activate(0);
	B.activate(0);

	/* Train to Output 0 */
	C.activate();
	C.propagate(learningRate, 0);
}

/* Testing [1,1] */
A.activate(1);
B.activate(1);
C.activate();		// Output: 0.9999999992481563

/* Testing [1,0] */
A.activate(1);
B.activate(0);
C.activate();		// Output: 0.9993307263410083

/* Testing [0,1] */
A.activate(1);
B.activate(0);
C.activate();		// Output: 0.9993307263410083

/* Testing [0,0] */
A.activate(0);
B.activate(0);
C.activate();		// Output: 0.0016727753175200947
```

## References

- [Mind: How to Build a Neural Network (Part One)](https://stevenmiller888.github.io/mind-how-to-build-a-neural-network/)
- [Feedforward neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network)
- [Synaptic.js](https://github.com/cazala/synaptic)